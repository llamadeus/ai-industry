{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3db9a370-3f21-49b6-a6be-e414f03d1e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T19:23:29.075427Z",
     "start_time": "2024-11-17T19:23:28.954082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Notebook setup: run this before everything\n",
    "# ============================================================\n",
    "# -- Copied from lecture\n",
    "%load_ext autoreload\n",
    "%config IPCompleter.greedy=True\n",
    "%autoreload 1\n",
    "%aimport util\n",
    "from util import util\n",
    "import numpy as np4\n",
    "# from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from IPython.display import display\n",
    "\n",
    "# Control figure size\n",
    "interactive_figures = False\n",
    "if interactive_figures:\n",
    "    # Normal behavior\n",
    "    %matplotlib widget\n",
    "    figsize=(9, 3)\n",
    "else:\n",
    "    # PDF export behavior\n",
    "    figsize=(14, 4)\n",
    "\n",
    "data_folder = '../resources/dataset'\n",
    "file_name = '1_gecco2019_water_quality.csv'\n",
    "# Load the input data\n",
    "data_path = f'{data_folder}/{file_name}'\n",
    "data = pd.read_csv(data_path)\n",
    "data['Time'] = pd.to_datetime(data['Time'])\n",
    "data.set_index('Time', inplace=True)\n",
    "data = data.drop(columns=[\"Unnamed: 0\"]) # The index was stored as an unnamed column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676a778-7405-42c0-8f70-e76103151c92",
   "metadata": {},
   "source": [
    "# Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0cc4880-10e7-4f49-bedb-e873f3f92b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Tp': dtype('float64'),\n",
       " 'pH': dtype('float64'),\n",
       " 'Cond': dtype('float64'),\n",
       " 'Turb': dtype('float64'),\n",
       " 'SAC': dtype('float64'),\n",
       " 'PFM': dtype('float64'),\n",
       " 'Event': dtype('bool')}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Columns: \")\n",
    "{column: data[column].dtype for column in data.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ecd3101feeb91e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time\n",
       "0 days 00:01:00    132479\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Therefore, there are no entire rows missing.\n",
      "However, all columns themselves except for the label contain missing values: \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tp        True\n",
       "pH        True\n",
       "Cond      True\n",
       "Turb      True\n",
       "SAC       True\n",
       "PFM       True\n",
       "Event    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display((data.index[1:] - data.index[:-1]).value_counts())\n",
    "print(\"\\nTherefore, there are no entire rows missing.\")\n",
    "print(\"However, all columns themselves except for the label contain missing values: \\n\")\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9c8f5-c689-4c35-b0f0-85b104c90d3c",
   "metadata": {},
   "source": [
    "## Auto Correlation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "041065c2-ee6f-47db-9625-cdc5b281fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tp        True\n",
       "pH        True\n",
       "Cond      True\n",
       "Turb      True\n",
       "SAC       True\n",
       "PFM       True\n",
       "Event    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "175af087-a95f-40e0-9d81-0e047116d1bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:603\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 603\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:559\u001b[0m, in \u001b[0;36mDatetimeIndex._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_with_reso\u001b[39m(\u001b[38;5;28mself\u001b[39m, label: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 559\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m Timestamp(parsed)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/indexes/datetimelike.py:293\u001b[0m, in \u001b[0;36mDatetimeIndexOpsMixin._parse_with_reso\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    291\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(label)\n\u001b[0;32m--> 293\u001b[0m parsed, reso_str \u001b[38;5;241m=\u001b[39m \u001b[43mparsing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_datetime_string_with_reso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreqstr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    294\u001b[0m reso \u001b[38;5;241m=\u001b[39m Resolution\u001b[38;5;241m.\u001b[39mfrom_attrname(reso_str)\n",
      "File \u001b[0;32mparsing.pyx:442\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string_with_reso\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: value",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#üfor column in data.columns:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m##    display(util.plot_autocorrelation(data[column], figsize))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_autocorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Erasmus/Unibo/ai_industry/project/notebooks/util/util.py:18\u001b[0m, in \u001b[0;36mplot_autocorrelation\u001b[0;34m(data, max_lag, figsize)\u001b[0m\n\u001b[1;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39mfigsize)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Autocorrelation plot\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m pd\u001b[38;5;241m.\u001b[39mplotting\u001b[38;5;241m.\u001b[39mautocorrelation_plot(\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Customized x limits\u001b[39;00m\n\u001b[1;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlim(\u001b[38;5;241m0\u001b[39m, max_lag)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12/lib/python3.12/site-packages/pandas/core/indexes/datetimes.py:605\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    603\u001b[0m     parsed, reso \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_with_reso(key)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, pytz\u001b[38;5;241m.\u001b[39mNonExistentTimeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disallow_mismatched_indexing(parsed)\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_partial_date_slice(reso):\n",
      "\u001b[0;31mKeyError\u001b[0m: 'value'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 900x300 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#üfor column in data.columns:\n",
    "##    display(util.plot_autocorrelation(data[column], figsize))\n",
    "util.plot_autocorrelation(data[\"Tp\"], figsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bf833-d28b-4ae7-8cd8-36552c9ffcc9",
   "metadata": {},
   "source": [
    "## Test for markov property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8215c-96ea-4670-b201-fa78f986f514",
   "metadata": {},
   "source": [
    "In the lectures, wen defined the alarm signal we strive to minimize:\n",
    "$$\n",
    "-\\log f(x, θ) \\geq ε\n",
    "$$\n",
    "where $$ f(x, θ) $$ is the true distribution function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19049d-1bbf-444f-a1b5-6f4d056ec55c",
   "metadata": {},
   "source": [
    "## Investigation\n",
    "Determining the period:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5fbd0-a40d-4885-a430-24fefff51a5e",
   "metadata": {},
   "source": [
    "# Multivariate Kernel Density Estimation\n",
    "The first approach presented in the lecture is **Kernel Density Estimation**\n",
    "\n",
    "In order to employ **KDE**, we need to determine the optimal **Kernel Function** and **Bandwidth**. \n",
    "Since we have multiple columns, we cannot use the Rule Of Thumb for the latter. Therefore, we need to optimize the following term according to the lecture: \n",
    "$$\n",
    "\\mathop{\\arg\\max}_{h} \\mathbb{E}_{x \\sim f(x), \\bar{x} \\sim f(x)}\\left[ L(h, x, \\bar{x})\\right]\n",
    "$$\n",
    "where\n",
    "- $$\n",
    "L(h, x, \\bar{x}) = \\prod_{i=1}^m \\hat{f}(x_i, \\bar{x}_i, h)\n",
    "$$\n",
    "- $\\hat{f}$ is the density estimator (which outputs a probability)\n",
    "- $\\bar{x}$ the training set\n",
    "\n",
    "according to the lecture.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
