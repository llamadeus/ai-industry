{
 "cells": [
  {
   "cell_type": "code",
   "id": "3db9a370-3f21-49b6-a6be-e414f03d1e61",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Notebook setup: run this before everything\n",
    "# ============================================================\n",
    "# -- Copied from lecture\n",
    "%load_ext autoreload\n",
    "%config IPCompleter.greedy=True\n",
    "%autoreload 1\n",
    "%aimport util\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from util import util\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Control figure size\n",
    "interactive_figures = False\n",
    "if interactive_figures:\n",
    "    # Normal behavior\n",
    "    %matplotlib widget\n",
    "    figsize=(9, 3)\n",
    "else:\n",
    "    # PDF export behavior\n",
    "    figsize=(14, 4)\n",
    "\n",
    "raw_data = util.load_dataset('7_gecco2019_train_water_quality.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2212816f",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models\n",
    "Gaussian Mixture Models (GMM) are a popular unsupervised learning algorithm that can be used to model the distribution of a dataset. In the context of anomaly detection, GMM can be used to find clusters of normal data points and identify anomalies. GMMs describe the distribution via a weighted sum of Gaussian components.\n",
    "\n",
    "GMMs assume, that data is generated by the following probabilistic model:\n",
    "$$\n",
    "X_Z,\n",
    "$$\n",
    "where both $Z$ and $X_Z$ are random variables. $Z$ is a latent variable that represents the component of the data, while $X_Z$ is the observed data. The latent variable $Z$ is assumed to be generated by a probability distribution $p(Z)$, while $X_Z$ follows a multivariate Gaussian distribution.\n",
    "\n",
    "In mathematical terms, a GMM is a probability distribution that can be represented as:\n",
    "$$\n",
    "g(x, \\mu, \\Sigma, \\tau) = \\sum_{k=1}^{n} \\tau_{k} \\mathcal{f}(x, \\mu_{k}, \\Sigma_{k}),\n",
    "$$\n",
    "where $\\tau$ is a vector of weights, $\\mu$ is a vector of means, $\\Sigma$ is a covariance matrix, and $\\mathcal{f}$ is the Gaussian probability density function."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "378ba5d0912860da"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preprocessing\n",
    "In order to use GMM for anomaly detection, we first need to make sure, that our data is free from missing values. As seen before, a linear interpolation approach yields the best results. Therefore, we will interpolate missing values using this method. Then, we have to apply a sliding window approach using the `aggregation_length` parameter explained above and aggregate the data into windows. This makes sure that we capture temporal correlations between data points and additionally removes noise in the data. The final step of our preprocessing pipeline is to standardize the data."
   ],
   "id": "8404782eff05530c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preprocess the data (interpolating missing values and applying sliding window)\n",
    "gmm_data_df = util.impute_missing_values(raw_data)\n",
    "gmm_data_df = util.apply_sliding_window_and_aggregate(gmm_data_df)\n",
    "\n",
    "# Identify the features to be used for GMM\n",
    "gmm_features = util.get_feature_columns(gmm_data_df)\n",
    "\n",
    "# Standardize the data (GMM assumes normally distributed data)\n",
    "gmm_scaler = StandardScaler()\n",
    "gmm_data_df[gmm_features] = gmm_scaler.fit_transform(gmm_data_df[gmm_features])\n",
    "\n",
    "print(gmm_data_df.head())"
   ],
   "id": "188a4c7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Determine the number of Gaussians\n",
    "Next, we need to determine the number of Gaussians to use for our GMM. We can do this using the Bayesian Information Criterion (BIC) or the elbow method. The BIC is a measure of the model's goodness of fit, while the elbow method is a visual tool that helps us determine the optimal number of Gaussians. In our case, we will use the BIC method."
   ],
   "id": "3689a93e482d8f6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select only relevant features (mean and variance).\n",
    "X = gmm_data_df[gmm_features]\n",
    "\n",
    "# Fit GMM and determine optimal K using BIC.\n",
    "lowest_bic = np.inf\n",
    "best_k = None\n",
    "\n",
    "# Try GMMs with 1 to 10 components.\n",
    "for k in range(1, 11):\n",
    "    gmm = GaussianMixture(n_components=k, covariance_type='full', random_state=42)\n",
    "    gmm.fit(X)\n",
    "\n",
    "    bic = gmm.bic(X)\n",
    "\n",
    "    # Do we have a better model?\n",
    "    if bic < lowest_bic:\n",
    "        lowest_bic = bic\n",
    "        best_k = k\n",
    "\n",
    "print(f\"Best GMM with {best_k} components, BIC: {lowest_bic:.2f}\")"
   ],
   "id": "3913ab42c989abf9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the GMM\n",
    "Next, we train the GMM with the optimal number of components. Additionally, we compute the log likelihood scores for each data point. This score is a measure of how likely a data point is to be generated by the Gaussian distribution. Higher scores indicate a higher likelihood of being generated by a Gaussian distribution."
   ],
   "id": "96e79a9b5b63a9fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train GMM with best K.\n",
    "best_k = 7\n",
    "final_gmm = GaussianMixture(n_components=best_k, covariance_type='full', random_state=42)\n",
    "final_gmm.fit(X)\n",
    "\n",
    "# Compute likelihood scores for the training data.\n",
    "log_likelihood = final_gmm.score_samples(X)"
   ],
   "id": "bbc0d8a56786f859",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Threshold optimization\n",
    "Now, we need to define a threshold to separate normal data from anomalous data. We will use a simple threshold optimization approach. First, we define the percentiles to test. Then, we compute precision, recall, and F1 scores for each percentile. These are the preferred metrics when working with big class imbalances. Finally, we select the percentile with the highest F1 score."
   ],
   "id": "63b81c200a2cb339"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define percentiles to test.\n",
    "percentiles = np.arange(0.1, 2.1, 0.1)\n",
    "\n",
    "# For storing the results.\n",
    "results = []\n",
    "\n",
    "for p in percentiles:\n",
    "    # Get predictions and threshold\n",
    "    y_pred, threshold = util.get_predictions_from_log_likelihood(log_likelihood, p)\n",
    "\n",
    "    # Compute performance\n",
    "    f1, precision, recall = util.compute_model_performance(y_pred, gmm_data_df['Event'])\n",
    "\n",
    "    # Store results.\n",
    "    results.append((p, threshold, precision, recall, f1))\n",
    "\n",
    "# Convert to DataFrame for better visualization.\n",
    "df_results = pd.DataFrame(results, columns=['Percentile', 'Threshold', 'Precision', 'Recall', 'F1-score'])\n",
    "\n",
    "# Display results.\n",
    "gmm_best_percentile = df_results.loc[df_results['F1-score'].idxmax()]\n",
    "print(df_results)\n",
    "print(f\"Best GMM model with percentile {gmm_best_percentile['Percentile']} and threshold {gmm_best_percentile['Threshold']} achieves an F1-score of {gmm_best_percentile['F1-score']}\")"
   ],
   "id": "4a8eb81a94a2b7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Compute number of anomalies\n",
    "Now, we compute the number of anomalies for the identified threshold."
   ],
   "id": "28d623974cc404e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute number of anomalies\n",
    "threshold = np.percentile(log_likelihood, gmm_best_percentile['Percentile'])\n",
    "anomalies = log_likelihood < threshold\n",
    "\n",
    "print(f\"Anomaly threshold: {threshold:.2f}\")\n",
    "print(f\"Number of anomalies: {np.sum(anomalies)}\")\n",
    "\n",
    "# Add anomaly labels to DataFrame\n",
    "gmm_data_df['Anomaly_Score'] = log_likelihood\n",
    "gmm_data_df['Anomaly'] = anomalies\n",
    "\n",
    "print(gmm_data_df['Anomaly_Score'].head())"
   ],
   "id": "c6b1efbbc83604d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Confusion Matrix and Classification Report\n",
    "To measure the performance of our anomaly detection model on the training data, we can use the confusion matrix and classification report."
   ],
   "id": "b7b4c747c7765ea9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert Boolean to integers for evaluation\n",
    "y_true = gmm_data_df['Event'].astype(int)  # Actual contamination events\n",
    "y_pred = gmm_data_df['Anomaly'].astype(int)  # Detected anomalies\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
   ],
   "id": "84a73c1a5f87a962",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The GMM performed well on the training data with a high overall accuracy of 99%, but this is primarily due to the class imbalance that favors normal samples. The model correctly classified nearly all normal cases (TN = 131,397) with a precision of 1.00. This indicates relatively few false positives (FP = 745). However, while it detected 56% of actual anomalies (recall = 0.56), it still missed 44% (FN = 146). The precision for anomalies (0.20) suggests that only one-fifth of the detected anomalies were true contaminations, meaning there are still false alarms. The F1-score of 0.29 shows a weaker balance between precision and recall. We can conclude that the model is moderately effective at detecting anomalies in the training set, but further improvements may be needed for generalization to unseen data.",
   "id": "5d4c69b280db4070"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Performance on Test Data\n",
    "The lack of generalization can be seen when we test the trained GMM on the test data. First, we have to perform the same preprocessing steps as with the training data. Afterwards, we can apply the GMM to the test data and compute the confusion matrix and classification report."
   ],
   "id": "69f53cfca7dd602a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load test data\n",
    "test_data = util.load_dataset('6_gecco2019_test_water_quality.csv')\n",
    "\n",
    "# Preprocess test data\n",
    "gmm_test_data_df = util.impute_missing_values(test_data)\n",
    "gmm_test_data_df = util.apply_sliding_window_and_aggregate(gmm_test_data_df)\n",
    "\n",
    "# Standardize the data (GMM assumes normally distributed data)\n",
    "gmm_test_data_df[gmm_features] = gmm_scaler.transform(gmm_test_data_df[gmm_features])\n",
    "\n",
    "# Compute scores for test data\n",
    "X_test = gmm_test_data_df[gmm_features]\n",
    "log_likelihood_test = final_gmm.score_samples(X_test)  # Higher is more normal, lower is more anomalous\n",
    "\n",
    "threshold_test = np.percentile(log_likelihood_test, 1)  # This time use the 1% percentile as cutoff\n",
    "anomalies_test = log_likelihood_test < threshold_test\n",
    "\n",
    "# Add anomaly labels to DataFrame\n",
    "gmm_test_data_df['Anomaly_Score'] = log_likelihood_test\n",
    "gmm_test_data_df['Anomaly'] = anomalies_test\n",
    "\n",
    "# Convert Boolean to integers for evaluation\n",
    "y_true = gmm_test_data_df['Event'].astype(int)  # Actual contamination events\n",
    "y_pred = gmm_test_data_df['Anomaly'].astype(int)  # Detected anomalies\n",
    "\n",
    "# Print performance metrics\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))"
   ],
   "id": "6f9bf144b7a2983e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "On the test data, the performance of the GMM dropped significantly, with anomaly recall dropping to 31%. The model failed to detect most contaminants (FN = 206). While normal samples were still well classified (99% accuracy for class 0), anomaly precision was only 29%, indicating a high false positive rate. The F1-score of 0.30 confirms that the model struggles to generalize, probably due to overfitting on training data. These results suggest that the model needs better generalization techniques, such as adjusting the threshold, retraining with a more balanced dataset, or considering alternative anomaly detection methods.",
   "id": "2dade5d75f7347c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anomaly_detection_for_contamination_detect-I_ojTiUE-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
